from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.applications import imagenet_utils
from tensorflow.keras.preprocessing.image import img_to_array
from imutils.object_detection import non_max_suppression
import numpy as np
import argparse
import cv2
import tensorflow as tf
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.compat.v1.Session(config=config)

def selective_search(image,method="fast"):
    # running selective search on the input image and setting the input as base image
    ss=cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
    ss.setBaseImage(image)
    # switching to the version of selective search to be implemented
    if method=="fast":
        ss.switchToSelectiveSearchFast()
    else:
        ss.switchToSelectiveSearchQuality()
    # running selective search on the input image
    rects=ss.process()
    #return the bounding boxes of the region proposals (ROIs)
    return rects

# arguements for input
ap=argparse.ArgumentParser()
ap.add_argument("-i","--image",required=True,help="path to input image")
ap.add_argument("-m","--method",default="fast",type=str,choices=["quality","fast"],help="selective search method required for region proposal")
ap.add_argument("-c","--conf",type=float,default=0.9,help="minimum threshold for confirming the image detection")
ap.add_argument("-f","--filter",type=str,default=None,help="comma separated labels which the detector should ignore")

args=vars(ap.parse_args())

# gathering the label filters 
labelFilters=args["filter"]
if labelFilters is not None:
    labelFilters=labelFilters.lower().split(",")
print(labelFilters)
#loading the resnet
print("[INFO] loading resnet...")
model = ResNet50(weights="imagenet")

#loading the image and stroing its dimensions
image=cv2.imread(args["image"])
(H,W)=image.shape[:2]

# running selective search on it and returning the bounding boxes
print("[INFO] performing selective search on the given image using *{}* method".format(args["method"]))
rects=selective_search(image,method=args["method"])
print("[INFO] {} regions detected by selective search".format(len(rects)))

#initializing list of region proposals to be classified with their bounding boxes
proposals=[]
boxes=[]

# looping over region proposal bounding boxes coordinates generated by running selective search
for (x,y,w,h) in rects:
    # filtering the unusable boxes
    # filtering the boxes with size less than 10% of the size of the image
    if w/float(W)<0.1 or h/float(H)<0.1:
        continue
    # extracting regions of interest from the input image and converting it from BGR to RGB
    # resizing it 224x224 shape, required by the classifier
    roi=image[y:y+h,x:x+w]
    roi=cv2.cvtColor(roi,cv2.COLOR_BGR2RGB)
    roi=cv2.resize(roi,(224,224))

    # further preprocessing required
    roi=img_to_array(roi)
    roi=preprocess_input(roi)

    #updating list of bounding boxes and proposals
    proposals.append(roi)
    boxes.append((x,y,w,h))

# converting the list of proposals to a numpy array
proposals=np.array(proposals)
print("[INFO] proposals shape {}".format(proposals.shape))

# classifying each proposal ROIs using ResNet and decoding the predictions
print("[INFO] classifying proposals...")
preds=model.predict(proposals)
preds=imagenet_utils.decode_predictions(preds,top=1)
# initializing a dictionary to map class labels to bounding box associated with it
labels={}

#looping over predictions
for (i,p) in enumerate(preds):
    # copying info of the prediction
    (imagenetID,label,probs)=p[0]
    
    # if label filters are not empty and label doesn't exist in list, ignore it
    if labelFilters is not None and label not in labelFilters:
        continue
    #filter the weak detections 
    if probs>=args["conf"]:
        # if the prediction passes through, take the coordinates
        (x,y,w,h)=boxes[i]
        box=(x,y,x+w,y+h)
        # list of predictions for the particular label, adding a bounding box and probability of that label to the list
        L=labels.get(label,[])
        L.append((box,probs))
        labels[label]=L

# looping over the labels for eacch detected objects in image
for label in labels.keys():
    # cloning the image to show output on it
    print("[INFO] showing results for '{}'".format(label))
    clone=image.copy()

    # looping over all bounding boxes for current label
    for (box,prob) in labels[label]:
        #drawing bounding box on the image
        (startX,startY,endX,endY)=box
        cv2.rectangle(clone,(startX,startY),(endX,endY),(0,255,0),2) # green colored box

        # showing results before applying non-maxima suppression
        # cloning and showing results after applying non-maxima suppression
        cv2.imshow("Before",clone)
        clone=image.copy()
        # take all bounding boxes and associated predictions
        # apply non-maxima suppression
        boxes=np.array([p[0] for p in labels[label]])
        proba=np.array([p[1] for p in labels[label]])
        boxes=non_max_suppression(boxes,proba)

        # looping over all bounding boxes kept after applying supression
        for (startX,startY,endX,endY) in boxes:
            # draw bounding box and label image
            cv2.rectangle(clone,(startX,startY),(endX,endY),(0,255,0),2)
            y=startY-10 if startY-10>10 else startY+10
            cv2.putText(clone,label,(startX,y),cv2.FONT_HERSHEY_SIMPLEX,0.45,(0,0,255),1)
        
    # showing output after applying non-maxima suppression
    cv2.imshow("After",clone)
    cv2.waitKey(0)